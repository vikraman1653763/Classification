{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_B4gBvmqAIo"
      },
      "source": [
        "# Team members\n",
        "\n",
        "\n",
        "*   Mahalakshmi M\n",
        "*   Pavithra M\n",
        "*   Sabthika R\n",
        "* Arun vishwa R\n",
        "*  Karthikeyan S\n",
        "*   Vikraman G\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D5KY674qflI"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFhf0wKicg6I"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ast import literal_eval\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Perform exploratory data analysis\n"
      ],
      "metadata": {
        "id": "IqEYlr8efFT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Eq2hjjB2dCPF",
        "outputId": "829bc872-5e87-4bb1-b3c5-69aafaa92f93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-882555ea-4971-4dec-ac61-e051948114a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-882555ea-4971-4dec-ac61-e051948114a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-882555ea-4971-4dec-ac61-e051948114a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-882555ea-4971-4dec-ac61-e051948114a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-afd78533-7d44-4805-8b1e-19669fb23b36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afd78533-7d44-4805-8b1e-19669fb23b36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-afd78533-7d44-4805-8b1e-19669fb23b36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "arxiv_data = pd.read_csv(\n",
        "    \"https://github.com/soumik12345/multi-label-text-classification/releases/download/v0.2/arxiv_data.csv\"\n",
        ")\n",
        "arxiv_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fmqHX8udYUm",
        "outputId": "457081dc-3d03-4c90-dcd1-e8efa4ca0adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 51774 rows in the dataset.\n"
          ]
        }
      ],
      "source": [
        "print(f\"There are {len(arxiv_data)} rows in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzT3qsPqdr2S",
        "outputId": "0ae4e10f-d115-442e-b5b3-f670fd67ff03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 12802 duplicate titles.\n"
          ]
        }
      ],
      "source": [
        "total_duplicate_titles = sum(arxiv_data[\"titles\"].duplicated())\n",
        "print(f\"There are {total_duplicate_titles} duplicate titles.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3EkOmkucH9J",
        "outputId": "c5d17160-c069-4e56-c662-740de775a9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 38972 rows in the deduplicated dataset.\n",
            "2321\n",
            "3157\n"
          ]
        }
      ],
      "source": [
        "arxiv_data = arxiv_data[~arxiv_data[\"titles\"].duplicated()]\n",
        "print(f\"There are {len(arxiv_data)} rows in the deduplicated dataset.\")\n",
        "\n",
        "# There are some terms with occurrence as low as 1.\n",
        "print(sum(arxiv_data[\"terms\"].value_counts() == 1))\n",
        "\n",
        "# How many unique terms?\n",
        "print(arxiv_data[\"terms\"].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeaFc_UreuMw",
        "outputId": "c4e72a1e-65bf-4e72-d408-a5a120526a8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36651, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Filtering the rare terms.\n",
        "arxiv_data_filtered = arxiv_data.groupby(\"terms\").filter(lambda x: len(x) > 1)\n",
        "arxiv_data_filtered.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exXdBlfaixtn"
      },
      "source": [
        "# Convert the string labels to lists of strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oXRYu3jezu7",
        "outputId": "6f77df73-c249-4b87-9347-1a45a42703b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['cs.CV', 'cs.LG']), list(['cs.CV', 'cs.AI', 'cs.LG']),\n",
              "       list(['cs.CV', 'cs.AI']), list(['cs.CV']),\n",
              "       list(['cs.CV', 'cs.LG'])], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "  arxiv_data_filtered[\"terms\"] = arxiv_data_filtered[\"terms\"].apply(\n",
        "      lambda x: literal_eval(x)\n",
        "  )\n",
        "  arxiv_data_filtered[\"terms\"].values[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use stratified splits because of class imbalance"
      ],
      "metadata": {
        "id": "ghhVPDTCfyDQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oToOW0H9e4d2",
        "outputId": "ef761524-aca1-45d3-842f-b30fb24224ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in training set: 32985\n",
            "Number of rows in validation set: 1833\n",
            "Number of rows in test set: 1833\n"
          ]
        }
      ],
      "source": [
        "test_split = 0.1\n",
        "\n",
        "# Initial train and test split.\n",
        "train_df, test_df = train_test_split(\n",
        "    arxiv_data_filtered,\n",
        "    test_size=test_split,\n",
        "    stratify=arxiv_data_filtered[\"terms\"].values,\n",
        ")\n",
        "\n",
        "# Splitting the test set further into validation\n",
        "# and new test sets.\n",
        "val_df = test_df.sample(frac=0.5)\n",
        "test_df.drop(val_df.index, inplace=True)\n",
        "\n",
        "print(f\"Number of rows in training set: {len(train_df)}\")\n",
        "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
        "print(f\"Number of rows in test set: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-label binarization"
      ],
      "metadata": {
        "id": "swNO0Vjtf44b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DSEDRwle91X",
        "outputId": "e0ccef55-2696-46de-d45e-dadacbbcc820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:\n",
            "\n",
            "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.CR', 'math.OC', 'eess.SP', 'cs.GR', 'cs.SI', 'cs.MM', 'cs.SY', 'cs.IR', 'cs.MA', 'eess.SY', 'cs.HC', 'math.IT', 'cs.IT', 'cs.DC', 'cs.CY', 'stat.AP', 'stat.TH', 'math.ST', 'stat.ME', 'eess.AS', 'cs.SD', 'q-bio.QM', 'q-bio.NC', 'cs.DS', 'cs.GT', 'cs.CG', 'cs.NI', 'cs.SE', 'stat.CO', 'I.2.6', 'math.NA', 'cs.NA', 'physics.chem-ph', 'cs.DB', 'q-bio.BM', 'cs.LO', 'cs.PL', 'cond-mat.dis-nn', '68T45', 'math.PR', 'physics.comp-ph', 'cs.CE', 'cs.AR', 'I.2.10', 'q-fin.ST', 'cond-mat.stat-mech', 'math.DS', '68T05', 'quant-ph', 'cs.CC', 'I.4.6', 'physics.soc-ph', 'physics.data-an', 'physics.ao-ph', 'econ.EM', 'cs.DM', 'q-bio.GN', 'physics.med-ph', 'astro-ph.IM', 'I.4.8', 'math.AT', 'cs.PF', 'cs.FL', 'I.4', 'q-fin.TR', 'I.5.4', 'I.2', '68U10', 'hep-ex', 'cond-mat.mtrl-sci', '68T10', 'physics.geo-ph', 'physics.optics', 'physics.flu-dyn', 'math.AP', 'I.4; I.5', 'I.4.9', 'I.2.6; I.2.8', '68T01', '65D19', 'q-fin.CP', 'nlin.CD', 'math.CO', 'cs.MS', 'I.2.6; I.5.1', 'I.2.10; I.4; I.5', 'I.2.0; I.2.6', '68T07', 'cs.SC', 'cs.ET', 'K.3.2', 'I.2; I.5', 'I.2.8', '68U01', '68T30', 'q-fin.GN', 'q-fin.EC', 'q-bio.MN', 'econ.GN', 'I.4.9; I.5.4', 'I.4.5', 'I.2; I.4; I.5', 'I.2.6; I.2.7', 'I.2.10; I.4.8', '68T99', '68Q32', '68', '62H30', 'q-fin.RM', 'q-fin.PM', 'q-bio.TO', 'q-bio.OT', 'physics.bio-ph', 'nlin.AO', 'math.LO', 'math.FA', 'hep-ph', 'cond-mat.soft', 'I.4.6; I.4.8', 'I.4.4', 'I.4.3', 'I.4.0', 'I.2; J.2', 'I.2; I.2.6; I.2.7', 'I.2.7', 'I.2.6; I.5.4', 'I.2.6; I.2.9', 'I.2.6; I.2.7; H.3.1; H.3.3', 'I.2.6; I.2.10', 'I.2.6, I.5.4', 'I.2.1; J.3', 'I.2.10; I.5.1; I.4.8', 'I.2.10; I.4.8; I.5.4', 'I.2.10; I.2.6', 'I.2.1', 'H.3.1; I.2.6; I.2.7', 'H.3.1; H.3.3; I.2.6; I.2.7', 'G.3', 'F.2.2; I.2.7', 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3', '68Txx', '62H99', '62H35', '14J60 (Primary) 14F05, 14J26 (Secondary)']\n"
          ]
        }
      ],
      "source": [
        "terms = tf.ragged.constant(train_df[\"terms\"].values)\n",
        "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
        "lookup.adapt(terms)\n",
        "vocab = lookup.get_vocabulary()\n",
        "\n",
        "\n",
        "def invert_multi_hot(encoded_labels):\n",
        "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
        "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
        "    return np.take(vocab, hot_indices)\n",
        "\n",
        "\n",
        "print(\"Vocabulary:\\n\")\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zwNPdzqfEf_",
        "outputId": "44ca50d5-e96f-42e1-9d31-12db0ec4a43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original label: ['cs.CV']\n",
            "Label-binarized representation: [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "sample_label = train_df[\"terms\"].iloc[0]\n",
        "print(f\"Original label: {sample_label}\")\n",
        "\n",
        "label_binarized = lookup([sample_label])\n",
        "print(f\"Label-binarized representation: {label_binarized}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing and tf.data.Dataset objects"
      ],
      "metadata": {
        "id": "uud_ZyVDf-TZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB6wV0B3fI4j",
        "outputId": "5837fc05-0585-4030-c138-1bce3c5d7599"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    32985.000000\n",
              "mean       156.597878\n",
              "std         41.530015\n",
              "min          5.000000\n",
              "25%        128.000000\n",
              "50%        154.000000\n",
              "75%        183.000000\n",
              "max        462.000000\n",
              "Name: summaries, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_df[\"summaries\"].apply(lambda x: len(x.split(\" \"))).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zow1G-fHkRCC"
      },
      "outputs": [],
      "source": [
        "max_seqlen = 150\n",
        "batch_size = 128\n",
        "padding_token = \"<pad>\"\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "\n",
        "def make_dataset(dataframe, is_train=True):\n",
        "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
        "    label_binarized = lookup(labels).numpy()\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (dataframe[\"summaries\"].values, label_binarized)\n",
        "    )\n",
        "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
        "    return dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbJReYS2kZc2"
      },
      "outputs": [],
      "source": [
        "train_dataset = make_dataset(train_df, is_train=True)\n",
        "validation_dataset = make_dataset(val_df, is_train=False)\n",
        "test_dataset = make_dataset(test_df, is_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preview"
      ],
      "metadata": {
        "id": "BXNb2uq-gHmt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npVXjFnGkiUX",
        "outputId": "c6556868-c6f1-4d10-8e3e-5a35b63f0c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract: b'Model-free reinforcement learning algorithms, such as Q-learning, perform\\npoorly in the early stages of learning in noisy environments, because much\\neffort is spent unlearning biased estimates of the state-action value function.\\nThe bias results from selecting, among several noisy estimates, the apparent\\noptimum, which may actually be suboptimal. We propose G-learning, a new\\noff-policy learning algorithm that regularizes the value estimates by\\npenalizing deterministic policies in the beginning of the learning process. We\\nshow that this method reduces the bias of the value-function estimation,\\nleading to faster convergence to the optimal value and the optimal policy.\\nMoreover, G-learning enables the natural incorporation of prior domain\\nknowledge, when available. The stochastic nature of G-learning also makes it\\navoid some exploration costs, a property usually attributed only to on-policy\\nalgorithms. We illustrate these ideas in several examples, where G-learning\\nresults in significant improvements of the convergence rate and the cost of the\\nlearning process.'\n",
            "Label(s): ['cs.LG' 'math.IT' 'cs.IT']\n",
            " \n",
            "Abstract: b'In this paper, we focus on learning product graphs from multi-domain data. We\\nassume that the product graph is formed by the Cartesian product of two smaller\\ngraphs, which we refer to as graph factors. We pose the product graph learning\\nproblem as the problem of estimating the graph factor Laplacian matrices. To\\ncapture local interactions in data, we seek sparse graph factors and assume a\\nsmoothness model for data. We propose an efficient iterative solver for\\nlearning sparse product graphs from data. We then extend this solver to infer\\nmulti-component graph factors with applications to product graph clustering by\\nimposing rank constraints on the graph Laplacian matrices. Although working\\nwith smaller graph factors is computationally more attractive, not all graphs\\nmay readily admit an exact Cartesian product factorization. To this end, we\\npropose efficient algorithms to approximate a graph by a nearest Cartesian\\nproduct of two smaller graphs. The efficacy of the developed framework is\\ndemonstrated using several numerical experiments on synthetic data and real\\ndata.'\n",
            "Label(s): ['cs.LG' 'eess.SP']\n",
            " \n",
            "Abstract: b'Inspired by the effectiveness of adversarial training in the area of\\nGenerative Adversarial Networks we present a new approach for learning feature\\nrepresentations in person re-identification. We investigate different types of\\nbias that typically occur in re-ID scenarios, i.e., pose, body part and camera\\nview, and propose a general approach to address them. We introduce an\\nadversarial strategy for controlling bias, named Bias-controlled Adversarial\\nframework (BCA), with two complementary branches to reduce or to enhance\\nbias-related features. The results and comparison to the state of the art on\\ndifferent benchmarks show that our framework is an effective strategy for\\nperson re-identification. The performance improvements are in both full and\\npartial views of persons.'\n",
            "Label(s): ['cs.CV']\n",
            " \n",
            "Abstract: b\"Learning about many things can provide numerous benefits to a reinforcement\\nlearning system. For example, learning many auxiliary value functions, in\\naddition to optimizing the environmental reward, appears to improve both\\nexploration and representation learning. The question we tackle in this paper\\nis how to sculpt the stream of experience---how to adapt the learning system's\\nbehavior---to optimize the learning of a collection of value functions. A\\nsimple answer is to compute an intrinsic reward based on the statistics of each\\nauxiliary learner, and use reinforcement learning to maximize that intrinsic\\nreward. Unfortunately, implementing this simple idea has proven difficult, and\\nthus has been the focus of decades of study. It remains unclear which of the\\nmany possible measures of learning would work well in a parallel learning\\nsetting where environmental reward is extremely sparse or absent. In this\\npaper, we investigate and compare different intrinsic reward mechanisms in a\\nnew bandit-like parallel-learning testbed. We discuss the interaction between\\nreward and prediction learners and highlight the importance of introspective\\nprediction learners: those that increase their rate of learning when progress\\nis possible, and decrease when it is not. We provide a comprehensive empirical\\ncomparison of 14 different rewards, including well-known ideas from\\nreinforcement learning and active learning. Our results highlight a simple but\\nseemingly powerful principle: intrinsic rewards based on the amount of learning\\ncan generate useful behavior, if each individual learner is introspective.\"\n",
            "Label(s): ['cs.LG' 'stat.ML' 'cs.AI']\n",
            " \n",
            "Abstract: b'Braille has empowered visually challenged community to read and write. But at\\nthe same time, it has created a gap due to widespread inability of non-Braille\\nusers to understand Braille scripts. This gap has fuelled researchers to\\npropose Optical Braille Recognition techniques to convert Braille documents to\\nnatural language. The main motivation of this work is to cement the\\ncommunication gap at academic institutions by translating personal documents of\\nblind students. This has been accomplished by proposing an economical and\\neffective technique which digitizes Braille documents using a smartphone\\ncamera. For any given Braille image, a dot detection mechanism based on Hough\\ntransform is proposed which is invariant to skewness, noise and other\\ndeterrents. The detected dots are then clustered into Braille cells using\\ndistance-based clustering algorithm. In succession, the standard physical\\nparameters of each Braille cells are estimated for feature extraction and\\nclassification as natural language characters. The comprehensive evaluation of\\nthis technique on the proposed dataset of 54 Braille scripts has yielded into\\naccuracy of 98.71%.'\n",
            "Label(s): ['cs.CV']\n",
            " \n"
          ]
        }
      ],
      "source": [
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "for i, text in enumerate(text_batch[:5]):\n",
        "    label = label_batch[i].numpy()[None, ...]\n",
        "    print(f\"Abstract: {text}\")\n",
        "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
        "    print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization"
      ],
      "metadata": {
        "id": "KD68K2LhgNvt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f_sPjD_kp06",
        "outputId": "a7dbd972-d3a2-4aaf-ffd9-88a8b3ef569f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153723\n"
          ]
        }
      ],
      "source": [
        "# Source: https://stackoverflow.com/a/18937309/7636462\n",
        "vocabulary = set()\n",
        "train_df[\"summaries\"].str.lower().str.split().apply(vocabulary.update)\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(vocabulary_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbJ91JhWkvcb"
      },
      "outputs": [],
      "source": [
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
        ")\n",
        "\n",
        "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
        "# training set.\n",
        "with tf.device(\"/CPU:0\"):\n",
        "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)\n",
        "test_dataset = test_dataset.map(\n",
        "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
        ").prefetch(auto)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a text classification model"
      ],
      "metadata": {
        "id": "zUU8vzwygSyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiPw34Chk74T"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_model():\n",
        "    shallow_mlp_model = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(512, activation=\"relu\"),\n",
        "            layers.Dense(256, activation=\"relu\"),\n",
        "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
        "        ]  # More on why \"sigmoid\" has been used here in a moment.\n",
        "    )\n",
        "    return shallow_mlp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGHv8KEQUTZ3"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVxMCRz_Vtv6",
        "outputId": "75f6239a-6743-44c6-b46b-216611a2d8d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "258/258 [==============================] - 574s 2s/step - loss: 0.0312 - binary_accuracy: 0.9901 - val_loss: 0.0185 - val_binary_accuracy: 0.9940\n",
            "Epoch 2/10\n",
            "258/258 [==============================] - 551s 2s/step - loss: 0.0032 - binary_accuracy: 0.9991 - val_loss: 0.0256 - val_binary_accuracy: 0.9937\n",
            "Epoch 3/10\n",
            "258/258 [==============================] - 537s 2s/step - loss: 7.6414e-04 - binary_accuracy: 0.9999 - val_loss: 0.0322 - val_binary_accuracy: 0.9938\n",
            "Epoch 4/10\n",
            "258/258 [==============================] - 522s 2s/step - loss: 3.1485e-04 - binary_accuracy: 1.0000 - val_loss: 0.0353 - val_binary_accuracy: 0.9937\n",
            "Epoch 5/10\n",
            "258/258 [==============================] - 522s 2s/step - loss: 1.5465e-04 - binary_accuracy: 1.0000 - val_loss: 0.0394 - val_binary_accuracy: 0.9939\n",
            "Epoch 6/10\n",
            "258/258 [==============================] - 521s 2s/step - loss: 1.1347e-04 - binary_accuracy: 1.0000 - val_loss: 0.0416 - val_binary_accuracy: 0.9939\n",
            "Epoch 7/10\n",
            "258/258 [==============================] - 523s 2s/step - loss: 7.7604e-05 - binary_accuracy: 1.0000 - val_loss: 0.0439 - val_binary_accuracy: 0.9939\n",
            "Epoch 8/10\n",
            "258/258 [==============================] - 503s 2s/step - loss: 5.6343e-05 - binary_accuracy: 1.0000 - val_loss: 0.0441 - val_binary_accuracy: 0.9939\n",
            "Epoch 9/10\n",
            "258/258 [==============================] - 507s 2s/step - loss: 4.5336e-05 - binary_accuracy: 1.0000 - val_loss: 0.0459 - val_binary_accuracy: 0.9938\n",
            "Epoch 10/10\n",
            "129/258 [==============>...............] - ETA: 4:07 - loss: 3.4538e-05 - binary_accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "shallow_mlp_model = make_model()\n",
        "shallow_mlp_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"binary_accuracy\"]\n",
        ")\n",
        "\n",
        "history = shallow_mlp_model.fit(\n",
        "    train_dataset, validation_data=validation_dataset, epochs=epochs\n",
        ")\n",
        "\n",
        "\n",
        "def plot_result(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_result(\"loss\")\n",
        "plot_result(\"binary_accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "LOYdpoA5gYA5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyZxpeUlUcPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262253c6-b381-4d42-bdfc-9b81c722f2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 14s 905ms/step - loss: 0.0455 - binary_accuracy: 0.9937\n",
            "Categorical accuracy on the test set: 99.37%.\n"
          ]
        }
      ],
      "source": [
        "_, binary_acc = shallow_mlp_model.evaluate(test_dataset)\n",
        "print(f\"Categorical accuracy on the test set: {round(binary_acc * 100, 2)}%.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "TCAZpdvbLTOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNvEozWqusyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe0435a-617e-477f-9724-1937c8fb1d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 115ms/step\n",
            "Abstract: b'Spatial-temporal data forecasting of traffic flow is a challenging task\\nbecause of complicated spatial dependencies and dynamical trends of temporal\\npattern between different roads. Existing frameworks typically utilize given\\nspatial adjacency graph and sophisticated mechanisms for modeling spatial and\\ntemporal correlations. However, limited representations of given spatial graph\\nstructure with incomplete adjacent connections may restrict effective\\nspatial-temporal dependencies learning of those models. To overcome those\\nlimitations, our paper proposes Spatial-Temporal Fusion Graph Neural Networks\\n(STFGNN) for traffic flow forecasting. SFTGNN could effectively learn hidden\\nspatial-temporal dependencies by a novel fusion operation of various spatial\\nand temporal graphs, which is generated by a data-driven method. Meanwhile, by\\nintegrating this fusion graph module and a novel gated convolution module into\\na unified layer, SFTGNN could handle long sequences. Experimental results on\\nseveral public traffic datasets demonstrate that our method achieves\\nstate-of-the-art performance consistently than other baselines.'\n",
            "Label(s): ['cs.LG' 'cs.AI']\n",
            "Predicted Label(s): (cs.LG, cs.AI, cs.CV)\n",
            " \n",
            "Abstract: b\"Personalized recommendation system has become pervasive in various video\\nplatform. Many effective methods have been proposed, but most of them didn't\\ncapture the user's multi-level interest trait and dependencies between their\\nviewed micro-videos well. To solve these problems, we propose a Self-over-Co\\nAttention module to enhance user's interest representation. In particular, we\\nfirst use co-attention to model correlation patterns across different levels\\nand then use self-attention to model correlation patterns within a specific\\nlevel. Experimental results on filtered public datasets verify that our\\npresented module is useful.\"\n",
            "Label(s): ['cs.CV' 'cs.IR']\n",
            "Predicted Label(s): (cs.LG, cs.CV, stat.ML)\n",
            " \n",
            "Abstract: b'We present a self-supervised learning approach for optical flow. Our method\\ndistills reliable flow estimations from non-occluded pixels, and uses these\\npredictions as ground truth to learn optical flow for hallucinated occlusions.\\nWe further design a simple CNN to utilize temporal information from multiple\\nframes for better flow estimation. These two principles lead to an approach\\nthat yields the best performance for unsupervised optical flow learning on the\\nchallenging benchmarks including MPI Sintel, KITTI 2012 and 2015. More notably,\\nour self-supervised pre-trained model provides an excellent initialization for\\nsupervised fine-tuning. Our fine-tuned models achieve state-of-the-art results\\non all three datasets. At the time of writing, we achieve EPE=4.26 on the\\nSintel benchmark, outperforming all submitted methods.'\n",
            "Label(s): ['cs.CV' 'cs.LG']\n",
            "Predicted Label(s): (cs.CV, cs.LG, cs.SD)\n",
            " \n",
            "Abstract: b'In many machine learning applications, we are faced with incomplete datasets.\\nIn the literature, missing data imputation techniques have been mostly\\nconcerned with filling missing values. However, the existence of missing values\\nis synonymous with uncertainties not only over the distribution of missing\\nvalues but also over target class assignments that require careful\\nconsideration. In this paper, we propose a simple and effective method for\\nimputing missing features and estimating the distribution of target assignments\\ngiven incomplete data. In order to make imputations, we train a simple and\\neffective generator network to generate imputations that a discriminator\\nnetwork is tasked to distinguish. Following this, a predictor network is\\ntrained using the imputed samples from the generator network to capture the\\nclassification uncertainties and make predictions accordingly. The proposed\\nmethod is evaluated on CIFAR-10 and MNIST image datasets as well as five\\nreal-world tabular classification datasets, under different missingness rates\\nand structures. Our experimental results show the effectiveness of the proposed\\nmethod in generating imputations as well as providing estimates for the class\\nuncertainties in a classification task when faced with missing values.'\n",
            "Label(s): ['cs.LG' 'stat.ML' 'cs.AI']\n",
            "Predicted Label(s): (cs.LG, stat.ML, cs.AI)\n",
            " \n",
            "Abstract: b'We explore recurrent encoder multi-decoder neural network architectures for\\nsemi-supervised sequence classification and reconstruction. We find that the\\nuse of multiple reconstruction modules helps models generalize in a\\nclassification task when only a small amount of labeled data is available,\\nwhich is often the case in practice. Such models provide useful high-level\\nrepresentations of motions allowing clustering, searching and faster labeling\\nof new sequences. We also propose a new, realistic partitioning of a\\nwell-known, high quality motion-capture dataset for better evaluations. We\\nfurther explore a novel formulation for future-predicting decoders based on\\nconditional recurrent generative adversarial networks, for which we propose\\nboth soft and hard constraints for transition generation derived from desired\\nphysical properties of synthesized future movements and desired animation\\ngoals. We find that using such constraints allow to stabilize the training of\\nrecurrent adversarial architectures for animation generation.'\n",
            "Label(s): ['cs.CV' 'cs.LG']\n",
            "Predicted Label(s): (cs.CV, cs.LG, stat.ML)\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# Create a model for inference.\n",
        "model_for_inference = keras.Sequential([text_vectorizer, shallow_mlp_model])\n",
        "\n",
        "# Create a small dataset just for demoing inference.\n",
        "inference_dataset = make_dataset(test_df.sample(100), is_train=False)\n",
        "text_batch, label_batch = next(iter(inference_dataset))\n",
        "predicted_probabilities = model_for_inference.predict(text_batch)\n",
        "\n",
        "# Perform inference.\n",
        "for i, text in enumerate(text_batch[:5]):\n",
        "    label = label_batch[i].numpy()[None, ...]\n",
        "    print(f\"Abstract: {text}\")\n",
        "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
        "    predicted_proba = [proba for proba in predicted_probabilities[i]]\n",
        "    top_3_labels = [\n",
        "        x\n",
        "        for _, x in sorted(\n",
        "            zip(predicted_probabilities[i], lookup.get_vocabulary()),\n",
        "            key=lambda pair: pair[0],\n",
        "            reverse=True,\n",
        "        )\n",
        "    ][:3]\n",
        "    print(f\"Predicted Label(s): ({', '.join([label for label in top_3_labels])})\")\n",
        "    print(\" \")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}